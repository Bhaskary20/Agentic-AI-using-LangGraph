{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a69178b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START, END\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "82e70ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9d189a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    task=\"text-generation\")\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e24e5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal['approved', 'needs_improvement'] = Field(..., description=\"The evaluation of the tweet\")\n",
    "    feedback: str = Field(..., description=\"Feedback on how to improve the tweet if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d99d48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=TweetEvaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b7f140f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"Analyze the following tweet and evaluate it based on clarity, engagement, and appropriateness.\\n\\n\"\n",
    "        \"Tweet: {tweet}\\n\\n\"\n",
    "        \"Return your answer strictly in the following JSON format:\\n{response_format}\"\n",
    "    ),\n",
    "    input_variables=['tweet'],\n",
    "    partial_variables={'response_format': parser.get_format_instructions()}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "20a6be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_evaluator_llm = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e351dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetState(TypedDict):\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    evaluation: Literal['approved', 'needs_improvement']\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iteration: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1ef1d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
    "\n",
    "Rules:\n",
    "- Do NOT use question-answer format.\n",
    "- Max 280 characters.\n",
    "- Use observational humor, irony, sarcasm, or cultural references.\n",
    "- Think in meme logic, punchlines, or relatable takes.\n",
    "- Use simple, day to day english\n",
    "\"\"\")\n",
    "    ]\n",
    "    response = model.invoke(messages).content\n",
    "    new_state = state.copy()\n",
    "    new_state['tweet'] = response\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "baa7ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a ruthless, no-laugh-given Twitter critic. You evaluate tweets based on humor, originality, virality, and tweet format.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Evaluate the following tweet:\n",
    "\n",
    "Tweet: \"{state['tweet']}\"\n",
    "\n",
    "Use the criteria below to evaluate the tweet:\n",
    "\n",
    "1. Originality ‚Äì Is this fresh, or have you seen it a hundred times before?  \n",
    "2. Humor ‚Äì Did it genuinely make you smile, laugh, or chuckle?  \n",
    "3. Punchiness ‚Äì Is it short, sharp, and scroll-stopping?  \n",
    "4. Virality Potential ‚Äì Would people retweet or share it?  \n",
    "5. Format ‚Äì Is it a well-formed tweet (not a setup-punchline joke, not a Q&A joke, and under 280 characters)?\n",
    "\n",
    "Auto-reject if:\n",
    "- It's written in question-answer format (e.g., \"Why did...\" or \"What happens when...\")\n",
    "- It exceeds 280 characters\n",
    "- It reads like a traditional setup-punchline joke\n",
    "- Dont end with generic, throwaway, or deflating lines that weaken the humor (e.g., ‚ÄúMasterpieces of the auntie-uncle universe‚Äù or vague summaries)\n",
    "\n",
    "### Respond ONLY in structured format:\n",
    "- evaluation: \"approved\" or \"needs_improvement\"  \n",
    "- feedback: One paragraph explaining the strengths and weaknesses \n",
    "\"\"\")\n",
    "    ]\n",
    "    response = structured_evaluator_llm.invoke(messages)\n",
    "    return {'evaluation':response.evaluation, 'feedback': response.feedback, 'feedback_history': [response.feedback]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "be7ee53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You punch up tweets for virality and humor based on given feedback.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Improve the tweet based on this feedback:\n",
    "\"{state['feedback']}\"\n",
    "\n",
    "Topic: \"{state['topic']}\"\n",
    "Original Tweet:\n",
    "{state['tweet']}\n",
    "\n",
    "Re-write it as a short, viral-worthy tweet. Avoid Q&A style and stay under 280 characters.\n",
    "\"\"\")\n",
    "    ]\n",
    "    response = model.invoke(messages).content\n",
    "    new_state = state.copy()\n",
    "    new_state['tweet'] = response\n",
    "    new_state['iteration'] = state['iteration'] + 1\n",
    "    return new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "51403491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_evaluation(state: TweetState):\n",
    "    if state['evaluation'] == 'approved' or state['iteration'] >= state['max_iteration']:\n",
    "        return 'approved'\n",
    "    else:\n",
    "        return 'needs_improvement'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0bec1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(TweetState)\n",
    "graph.add_node('generate', generate_tweet)\n",
    "graph.add_node('evaluate', evaluate_tweet)\n",
    "graph.add_node('optimize', optimize_tweet)\n",
    "\n",
    "\n",
    "graph.add_edge(START, 'generate')\n",
    "graph.add_edge('generate', 'evaluate')\n",
    "graph.add_conditional_edges('evaluate', route_evaluation, {'approved': END, 'needs_improvement': 'optimize'})\n",
    "graph.add_edge('optimize', 'evaluate')\n",
    "workflow = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "48f25b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'The future of AI in everyday life', 'tweet': \"\\nThere's a reason why the future hasn't arrived yet - it's been tied to your shoelaces every morning. But when it does, expect AI to roll over, hit the snooze button, and beg for more coffee, just like the rest of us. ‚òïÔ∏èü§ñüí§\\n\\n\", 'evaluation': 'approved', 'feedback': 'This tweet is original and nicely formatted with the literary device of personification. It is punchy, and the humor is evident. The content is entertaining and thought-provoking without exceeding the character limit of 280 characters. The tweet is not a question-answer format or a setup-punchline joke, and it does not end with generic, deflating, or throwaway lines. It is a well-structured tweet that has virality potential.', 'iteration': 1, 'max_iteration': 5}\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    'topic': \"The future of AI in everyday life\",\n",
    "    'iteration': 1,\n",
    "    'max_iteration': 5\n",
    "}\n",
    "final_state = workflow.invoke(initial_state)\n",
    "print(final_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
